{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BmlItLXVEDwT"
   },
   "source": [
    "## Clone GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "NHVGNPKnVnRS",
    "outputId": "f56d985d-c1dd-4b07-bfec-b3a6e9463f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'fully_convolutional_network'...\n",
      "remote: Enumerating objects: 44, done.\u001b[K\n",
      "remote: Counting objects:   2% (1/44)\u001b[K\r",
      "remote: Counting objects:   4% (2/44)\u001b[K\r",
      "remote: Counting objects:   6% (3/44)\u001b[K\r",
      "remote: Counting objects:   9% (4/44)\u001b[K\r",
      "remote: Counting objects:  11% (5/44)\u001b[K\r",
      "remote: Counting objects:  13% (6/44)\u001b[K\r",
      "remote: Counting objects:  15% (7/44)\u001b[K\r",
      "remote: Counting objects:  18% (8/44)\u001b[K\r",
      "remote: Counting objects:  20% (9/44)\u001b[K\r",
      "remote: Counting objects:  22% (10/44)\u001b[K\r",
      "remote: Counting objects:  25% (11/44)\u001b[K\r",
      "remote: Counting objects:  27% (12/44)\u001b[K\r",
      "remote: Counting objects:  29% (13/44)\u001b[K\r",
      "remote: Counting objects:  31% (14/44)\u001b[K\r",
      "remote: Counting objects:  34% (15/44)\u001b[K\r",
      "remote: Counting objects:  36% (16/44)\u001b[K\r",
      "remote: Counting objects:  38% (17/44)\u001b[K\r",
      "remote: Counting objects:  40% (18/44)\u001b[K\r",
      "remote: Counting objects:  43% (19/44)\u001b[K\r",
      "remote: Counting objects:  45% (20/44)\u001b[K\r",
      "remote: Counting objects:  47% (21/44)\u001b[K\r",
      "remote: Counting objects:  50% (22/44)\u001b[K\r",
      "remote: Counting objects:  52% (23/44)\u001b[K\r",
      "remote: Counting objects:  54% (24/44)\u001b[K\r",
      "remote: Counting objects:  56% (25/44)\u001b[K\r",
      "remote: Counting objects:  59% (26/44)\u001b[K\r",
      "remote: Counting objects:  61% (27/44)\u001b[K\r",
      "remote: Counting objects:  63% (28/44)\u001b[K\r",
      "remote: Counting objects:  65% (29/44)\u001b[K\r",
      "remote: Counting objects:  68% (30/44)\u001b[K\r",
      "remote: Counting objects:  70% (31/44)\u001b[K\r",
      "remote: Counting objects:  72% (32/44)\u001b[K\r",
      "remote: Counting objects:  75% (33/44)\u001b[K\r",
      "remote: Counting objects:  77% (34/44)\u001b[K\r",
      "remote: Counting objects:  79% (35/44)\u001b[K\r",
      "remote: Counting objects:  81% (36/44)\u001b[K\r",
      "remote: Counting objects:  84% (37/44)\u001b[K\r",
      "remote: Counting objects:  86% (38/44)\u001b[K\r",
      "remote: Counting objects:  88% (39/44)\u001b[K\r",
      "remote: Counting objects:  90% (40/44)\u001b[K\r",
      "remote: Counting objects:  93% (41/44)\u001b[K\r",
      "remote: Counting objects:  95% (42/44)\u001b[K\r",
      "remote: Counting objects:  97% (43/44)\u001b[K\r",
      "remote: Counting objects: 100% (44/44)\u001b[K\r",
      "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
      "remote: Compressing objects:   3% (1/29)\u001b[K\r",
      "remote: Compressing objects:   6% (2/29)\u001b[K\r",
      "remote: Compressing objects:  10% (3/29)\u001b[K\r",
      "remote: Compressing objects:  13% (4/29)\u001b[K\r",
      "remote: Compressing objects:  17% (5/29)\u001b[K\r",
      "remote: Compressing objects:  20% (6/29)\u001b[K\r",
      "remote: Compressing objects:  24% (7/29)\u001b[K\r",
      "remote: Compressing objects:  27% (8/29)\u001b[K\r",
      "remote: Compressing objects:  31% (9/29)\u001b[K\r",
      "remote: Compressing objects:  34% (10/29)\u001b[K\r",
      "remote: Compressing objects:  37% (11/29)\u001b[K\r",
      "remote: Compressing objects:  41% (12/29)\u001b[K\r",
      "remote: Compressing objects:  44% (13/29)\u001b[K\r",
      "remote: Compressing objects:  48% (14/29)\u001b[K\r",
      "remote: Compressing objects:  51% (15/29)\u001b[K\r",
      "remote: Compressing objects:  55% (16/29)\u001b[K\r",
      "remote: Compressing objects:  58% (17/29)\u001b[K\r",
      "remote: Compressing objects:  62% (18/29)\u001b[K\r",
      "remote: Compressing objects:  65% (19/29)\u001b[K\r",
      "remote: Compressing objects:  68% (20/29)\u001b[K\r",
      "remote: Compressing objects:  72% (21/29)\u001b[K\r",
      "remote: Compressing objects:  75% (22/29)\u001b[K\r",
      "remote: Compressing objects:  79% (23/29)\u001b[K\r",
      "remote: Compressing objects:  82% (24/29)\u001b[K\r",
      "remote: Compressing objects:  86% (25/29)\u001b[K\r",
      "remote: Compressing objects:  89% (26/29)\u001b[K\r",
      "remote: Compressing objects:  93% (27/29)\u001b[K\r",
      "remote: Compressing objects:  96% (28/29)\u001b[K\r",
      "remote: Compressing objects: 100% (29/29)\u001b[K\r",
      "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
      "remote: Total 44 (delta 15), reused 38 (delta 12), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (44/44), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/himanshurawlani/fully_convolutional_network.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "trBcH3GLEPPV"
   },
   "source": [
    "## Change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "KqfuEh5pVvy7",
    "outputId": "4219755f-4f56-4280-a3cd-b73dc4ca6289"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/fully_convolutional_network\n",
      "['snapshots', 'export_savedmodel.py', 'README.md', 'generator.py', 'flower_classifier', '.git', 'model.py', 'utils.py', 'train.py', 'test_images', 'inference.py']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('fully_convolutional_network')\n",
    "print(os.getcwd())\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uAP4QM85Ea27"
   },
   "source": [
    "## Download and process dataset using utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "colab_type": "code",
    "id": "GLkaMqHkV0xi",
    "outputId": "add73865-d9f0-4eb7-dcf3-a22f663c0c16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://download.tensorflow.org/example_images/flower_photos.tgz\n",
      "228818944/228813984 [==============================] - 1s 0us/step\n",
      "Downloaded and extracted at ./datasets/flower_photos\n",
      "Copying images for dandelion...\n",
      "Copying images for daisy...\n",
      "Copying images for sunflowers...\n",
      "Copying images for roses...\n",
      "Copying images for tulips...\n",
      "Training dataset stats:\n",
      "\n",
      "--> Images in dandelion: 300\n",
      "--> Images in daisy: 300\n",
      "--> Images in sunflowers: 300\n",
      "--> Images in roses: 300\n",
      "--> Images in tulips: 300\n",
      "Validation dataset stats:\n",
      "--> Images in dandelion: 50\n",
      "--> Images in daisy: 50\n",
      "--> Images in sunflowers: 50\n",
      "--> Images in roses: 50\n",
      "--> Images in tulips: 50\n",
      "\n",
      "AVG_IMG_HEIGHT: 317\n",
      "AVG_IMG_WIDTH: 424\n",
      "MIN_HEIGHT: 180\n",
      "MIN_WIDTH: 146\n",
      "MAX_HEIGHT: 442\n",
      "MAX_WIDTH: 1024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dPhMgqD_Ehgj"
   },
   "source": [
    "## Train the FCN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4cQfQu-AWSjv",
    "outputId": "fda332dd-fe05-4ee1-ef4c-a59956d25f2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, None, None, 32)    896       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, None, None, 64)    18496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 1,608,005\n",
      "Trainable params: 1,604,869\n",
      "Non-trainable params: 3,136\n",
      "_________________________________________________________________\n",
      "None\n",
      "Total number of layers: 30\n",
      "2019-12-25 17:28:05.985566: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2019-12-25 17:28:05.987890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-25 17:28:05.988438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
      "pciBusID: 0000:00:04.0\n",
      "2019-12-25 17:28:05.988732: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2019-12-25 17:28:05.990767: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2019-12-25 17:28:05.992441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2019-12-25 17:28:05.992809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2019-12-25 17:28:05.994843: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2019-12-25 17:28:05.996139: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2019-12-25 17:28:06.000846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-12-25 17:28:06.000952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-25 17:28:06.001492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-25 17:28:06.001960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2019-12-25 17:28:06.002519: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
      "2019-12-25 17:28:06.010544: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000185000 Hz\n",
      "2019-12-25 17:28:06.010815: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19c2bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2019-12-25 17:28:06.010843: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2019-12-25 17:28:06.127261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-25 17:28:06.128307: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19c2d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2019-12-25 17:28:06.128351: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "2019-12-25 17:28:06.128677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-25 17:28:06.129426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
      "pciBusID: 0000:00:04.0\n",
      "2019-12-25 17:28:06.129550: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2019-12-25 17:28:06.129582: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2019-12-25 17:28:06.129612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2019-12-25 17:28:06.129637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2019-12-25 17:28:06.129663: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2019-12-25 17:28:06.129691: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2019-12-25 17:28:06.129740: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-12-25 17:28:06.129843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-25 17:28:06.130809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-25 17:28:06.131712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2019-12-25 17:28:06.131874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2019-12-25 17:28:06.134134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-12-25 17:28:06.134184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2019-12-25 17:28:06.134202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2019-12-25 17:28:06.134407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-25 17:28:06.135309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-25 17:28:06.136100: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2019-12-25 17:28:06.136152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14856 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
      "Epoch 1/50\n",
      "2019-12-25 17:28:08.382569: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2019-12-25 17:28:08.648450: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.8109 - acc: 0.3168Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 12s - loss: 2.1168 - acc: 0.2097\n",
      "Epoch 00001: val_loss improved from inf to 2.12913, saving model to ./snapshots/model_epoch_01_loss_1.81_acc_0.32_val_loss_2.13_val_acc_0.21.h5\n",
      "188/188 [==============================] - 74s 392ms/step - loss: 1.8119 - acc: 0.3172 - val_loss: 2.1291 - val_acc: 0.2070\n",
      "Epoch 2/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.5809 - acc: 0.3783Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.9552 - acc: 0.2177\n",
      "Epoch 00002: val_loss improved from 2.12913 to 1.97009, saving model to ./snapshots/model_epoch_02_loss_1.58_acc_0.38_val_loss_1.97_val_acc_0.21.h5\n",
      "188/188 [==============================] - 38s 201ms/step - loss: 1.5800 - acc: 0.3783 - val_loss: 1.9701 - val_acc: 0.2148\n",
      "Epoch 3/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.4272 - acc: 0.4318Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.7874 - acc: 0.2581\n",
      "Epoch 00003: val_loss improved from 1.97009 to 1.79373, saving model to ./snapshots/model_epoch_03_loss_1.43_acc_0.43_val_loss_1.79_val_acc_0.26.h5\n",
      "188/188 [==============================] - 38s 201ms/step - loss: 1.4304 - acc: 0.4309 - val_loss: 1.7937 - val_acc: 0.2578\n",
      "Epoch 4/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.3608 - acc: 0.4425Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.5810 - acc: 0.2944\n",
      "Epoch 00004: val_loss improved from 1.79373 to 1.58330, saving model to ./snapshots/model_epoch_04_loss_1.36_acc_0.44_val_loss_1.58_val_acc_0.29.h5\n",
      "188/188 [==============================] - 38s 201ms/step - loss: 1.3593 - acc: 0.4428 - val_loss: 1.5833 - val_acc: 0.2891\n",
      "Epoch 5/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2853 - acc: 0.4686Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.3487 - acc: 0.3790\n",
      "Epoch 00005: val_loss improved from 1.58330 to 1.35078, saving model to ./snapshots/model_epoch_05_loss_1.28_acc_0.47_val_loss_1.35_val_acc_0.39.h5\n",
      "188/188 [==============================] - 38s 201ms/step - loss: 1.2836 - acc: 0.4694 - val_loss: 1.3508 - val_acc: 0.3867\n",
      "Epoch 6/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2647 - acc: 0.4746Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.4959 - acc: 0.3508\n",
      "Epoch 00006: val_loss did not improve from 1.35078\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.2641 - acc: 0.4734 - val_loss: 1.4998 - val_acc: 0.3477\n",
      "Epoch 7/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2415 - acc: 0.4900Epoch 1/50\n",
      " 32/188 [====>.........................] - ETA: 7s - loss: 1.4531 - acc: 0.3828\n",
      "Epoch 00007: val_loss did not improve from 1.35078\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.2420 - acc: 0.4900 - val_loss: 1.4531 - val_acc: 0.3828\n",
      "Epoch 8/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2115 - acc: 0.5201Epoch 1/50\n",
      " 32/188 [====>.........................] - ETA: 7s - loss: 1.4337 - acc: 0.3594\n",
      "Epoch 00008: val_loss did not improve from 1.35078\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.2086 - acc: 0.5213 - val_loss: 1.4337 - val_acc: 0.3594\n",
      "Epoch 9/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.2146 - acc: 0.5100Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.3668 - acc: 0.4073\n",
      "Epoch 00009: val_loss did not improve from 1.35078\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.2140 - acc: 0.5106 - val_loss: 1.3717 - val_acc: 0.4141\n",
      "Epoch 10/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.1663 - acc: 0.5281Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.3012 - acc: 0.4798\n",
      "Epoch 00010: val_loss improved from 1.35078 to 1.30413, saving model to ./snapshots/model_epoch_10_loss_1.17_acc_0.53_val_loss_1.30_val_acc_0.49.h5\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.1667 - acc: 0.5273 - val_loss: 1.3041 - val_acc: 0.4883\n",
      "Epoch 11/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.1177 - acc: 0.5408Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.3089 - acc: 0.4194\n",
      "Epoch 00011: val_loss did not improve from 1.30413\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.1159 - acc: 0.5412 - val_loss: 1.3139 - val_acc: 0.4258\n",
      "Epoch 12/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.1352 - acc: 0.5381Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.1964 - acc: 0.4839\n",
      "Epoch 00012: val_loss improved from 1.30413 to 1.20009, saving model to ./snapshots/model_epoch_12_loss_1.14_acc_0.54_val_loss_1.20_val_acc_0.48.h5\n",
      "188/188 [==============================] - 38s 201ms/step - loss: 1.1364 - acc: 0.5379 - val_loss: 1.2001 - val_acc: 0.4844\n",
      "Epoch 13/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.1124 - acc: 0.5394Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.2828 - acc: 0.4194\n",
      "Epoch 00013: val_loss did not improve from 1.20009\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.1134 - acc: 0.5386 - val_loss: 1.2889 - val_acc: 0.4219\n",
      "Epoch 14/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.0894 - acc: 0.5501Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.2242 - acc: 0.4798\n",
      "Epoch 00014: val_loss did not improve from 1.20009\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.0882 - acc: 0.5505 - val_loss: 1.2263 - val_acc: 0.4844\n",
      "Epoch 15/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.0963 - acc: 0.5648Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.1866 - acc: 0.5403\n",
      "Epoch 00015: val_loss improved from 1.20009 to 1.18857, saving model to ./snapshots/model_epoch_15_loss_1.10_acc_0.56_val_loss_1.19_val_acc_0.55.h5\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.1008 - acc: 0.5625 - val_loss: 1.1886 - val_acc: 0.5469\n",
      "Epoch 16/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.0814 - acc: 0.5575Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.1512 - acc: 0.5565\n",
      "Epoch 00016: val_loss improved from 1.18857 to 1.14718, saving model to ./snapshots/model_epoch_16_loss_1.08_acc_0.56_val_loss_1.15_val_acc_0.56.h5\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.0813 - acc: 0.5578 - val_loss: 1.1472 - val_acc: 0.5625\n",
      "Epoch 17/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.0380 - acc: 0.5836Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.1261 - acc: 0.5242\n",
      "Epoch 00017: val_loss improved from 1.14718 to 1.12805, saving model to ./snapshots/model_epoch_17_loss_1.04_acc_0.59_val_loss_1.13_val_acc_0.53.h5\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.0356 - acc: 0.5851 - val_loss: 1.1281 - val_acc: 0.5312\n",
      "Epoch 18/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.0491 - acc: 0.5869Epoch 1/50\n",
      " 32/188 [====>.........................] - ETA: 7s - loss: 1.1116 - acc: 0.5859\n",
      "Epoch 00018: val_loss improved from 1.12805 to 1.11158, saving model to ./snapshots/model_epoch_18_loss_1.05_acc_0.59_val_loss_1.11_val_acc_0.59.h5\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.0488 - acc: 0.5871 - val_loss: 1.1116 - val_acc: 0.5859\n",
      "Epoch 19/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.0351 - acc: 0.5702Epoch 1/50\n",
      " 32/188 [====>.........................] - ETA: 7s - loss: 1.1593 - acc: 0.5156\n",
      "Epoch 00019: val_loss did not improve from 1.11158\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.0323 - acc: 0.5711 - val_loss: 1.1593 - val_acc: 0.5156\n",
      "Epoch 20/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.0419 - acc: 0.5949Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.1639 - acc: 0.5323\n",
      "Epoch 00020: val_loss did not improve from 1.11158\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.0412 - acc: 0.5957 - val_loss: 1.1695 - val_acc: 0.5391\n",
      "Epoch 21/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 1.0050 - acc: 0.5909Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.0548 - acc: 0.5927\n",
      "Epoch 00021: val_loss improved from 1.11158 to 1.05406, saving model to ./snapshots/model_epoch_21_loss_1.01_acc_0.59_val_loss_1.05_val_acc_0.60.h5\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.0056 - acc: 0.5904 - val_loss: 1.0541 - val_acc: 0.5977\n",
      "Epoch 22/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.9897 - acc: 0.6083Epoch 1/50\n",
      " 32/188 [====>.........................] - ETA: 7s - loss: 1.1159 - acc: 0.5820\n",
      "Epoch 00022: val_loss did not improve from 1.05406\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.9903 - acc: 0.6077 - val_loss: 1.1159 - val_acc: 0.5820\n",
      "Epoch 23/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.9908 - acc: 0.6163Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.1223 - acc: 0.5645\n",
      "Epoch 00023: val_loss did not improve from 1.05406\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.9894 - acc: 0.6157 - val_loss: 1.1220 - val_acc: 0.5664\n",
      "Epoch 24/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.9894 - acc: 0.6130Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.0270 - acc: 0.5766\n",
      "Epoch 00024: val_loss improved from 1.05406 to 1.03058, saving model to ./snapshots/model_epoch_24_loss_0.99_acc_0.61_val_loss_1.03_val_acc_0.58.h5\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.9887 - acc: 0.6137 - val_loss: 1.0306 - val_acc: 0.5820\n",
      "Epoch 25/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.9484 - acc: 0.6230Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.0396 - acc: 0.5887\n",
      "Epoch 00025: val_loss did not improve from 1.03058\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.9463 - acc: 0.6237 - val_loss: 1.0373 - val_acc: 0.5938\n",
      "Epoch 26/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.9379 - acc: 0.6290Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.0201 - acc: 0.6048\n",
      "Epoch 00026: val_loss improved from 1.03058 to 1.02437, saving model to ./snapshots/model_epoch_26_loss_0.94_acc_0.63_val_loss_1.02_val_acc_0.61.h5\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.9372 - acc: 0.6277 - val_loss: 1.0244 - val_acc: 0.6055\n",
      "Epoch 27/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.9123 - acc: 0.6377Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.0801 - acc: 0.5565\n",
      "Epoch 00027: val_loss did not improve from 1.02437\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.9104 - acc: 0.6376 - val_loss: 1.0759 - val_acc: 0.5586\n",
      "Epoch 28/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.9065 - acc: 0.6430Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.0038 - acc: 0.6008\n",
      "Epoch 00028: val_loss improved from 1.02437 to 1.00508, saving model to ./snapshots/model_epoch_28_loss_0.90_acc_0.64_val_loss_1.01_val_acc_0.60.h5\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.9046 - acc: 0.6436 - val_loss: 1.0051 - val_acc: 0.6016\n",
      "Epoch 29/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.9238 - acc: 0.6357Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 1.1096 - acc: 0.5524\n",
      "Epoch 00029: val_loss did not improve from 1.00508\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.9242 - acc: 0.6350 - val_loss: 1.1065 - val_acc: 0.5547\n",
      "Epoch 30/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.9222 - acc: 0.6451Epoch 1/50\n",
      " 32/188 [====>.........................] - ETA: 7s - loss: 0.9487 - acc: 0.6328\n",
      "Epoch 00030: val_loss improved from 1.00508 to 0.94868, saving model to ./snapshots/model_epoch_30_loss_0.92_acc_0.64_val_loss_0.95_val_acc_0.63.h5\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.9223 - acc: 0.6449 - val_loss: 0.9487 - val_acc: 0.6328\n",
      "Epoch 31/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.8983 - acc: 0.6511Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 0.9775 - acc: 0.6048\n",
      "Epoch 00031: val_loss did not improve from 0.94868\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.8973 - acc: 0.6509 - val_loss: 0.9756 - val_acc: 0.6055\n",
      "Epoch 32/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.8782 - acc: 0.6591Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 0.9488 - acc: 0.6048\n",
      "Epoch 00032: val_loss improved from 0.94868 to 0.94715, saving model to ./snapshots/model_epoch_32_loss_0.88_acc_0.66_val_loss_0.95_val_acc_0.61.h5\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.8803 - acc: 0.6582 - val_loss: 0.9472 - val_acc: 0.6094\n",
      "Epoch 33/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.8543 - acc: 0.6684Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 0.9889 - acc: 0.6008\n",
      "Epoch 00033: val_loss did not improve from 0.94715\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.8518 - acc: 0.6702 - val_loss: 0.9886 - val_acc: 0.6055\n",
      "Epoch 34/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.8784 - acc: 0.6484Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 0.8938 - acc: 0.6411\n",
      "Epoch 00034: val_loss improved from 0.94715 to 0.89358, saving model to ./snapshots/model_epoch_34_loss_0.88_acc_0.65_val_loss_0.89_val_acc_0.64.h5\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.8769 - acc: 0.6483 - val_loss: 0.8936 - val_acc: 0.6445\n",
      "Epoch 35/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.8559 - acc: 0.6638Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 0.9068 - acc: 0.6492\n",
      "Epoch 00035: val_loss did not improve from 0.89358\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.8536 - acc: 0.6656 - val_loss: 0.9046 - val_acc: 0.6523\n",
      "Epoch 36/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.8348 - acc: 0.6751Epoch 1/50\n",
      " 32/188 [====>.........................] - ETA: 7s - loss: 0.8586 - acc: 0.6484\n",
      "Epoch 00036: val_loss improved from 0.89358 to 0.85862, saving model to ./snapshots/model_epoch_36_loss_0.83_acc_0.68_val_loss_0.86_val_acc_0.65.h5\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.8339 - acc: 0.6762 - val_loss: 0.8586 - val_acc: 0.6484\n",
      "Epoch 37/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.8366 - acc: 0.6725Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 0.9598 - acc: 0.6290\n",
      "Epoch 00037: val_loss did not improve from 0.85862\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.8366 - acc: 0.6715 - val_loss: 0.9558 - val_acc: 0.6328\n",
      "Epoch 38/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.8109 - acc: 0.6818Epoch 1/50\n",
      " 32/188 [====>.........................] - ETA: 7s - loss: 0.9424 - acc: 0.6367\n",
      "Epoch 00038: val_loss did not improve from 0.85862\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.8109 - acc: 0.6822 - val_loss: 0.9424 - val_acc: 0.6367\n",
      "Epoch 39/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.8262 - acc: 0.6684Epoch 1/50\n",
      " 32/188 [====>.........................] - ETA: 7s - loss: 0.9246 - acc: 0.6133\n",
      "Epoch 00039: val_loss did not improve from 0.85862\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.8255 - acc: 0.6689 - val_loss: 0.9246 - val_acc: 0.6133\n",
      "Epoch 40/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.8047 - acc: 0.6811Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 0.8718 - acc: 0.6694\n",
      "Epoch 00040: val_loss did not improve from 0.85862\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.8071 - acc: 0.6802 - val_loss: 0.8776 - val_acc: 0.6719\n",
      "Epoch 41/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.8214 - acc: 0.6678Epoch 1/50\n",
      " 32/188 [====>.........................] - ETA: 7s - loss: 0.8467 - acc: 0.6797\n",
      "Epoch 00041: val_loss improved from 0.85862 to 0.84666, saving model to ./snapshots/model_epoch_41_loss_0.82_acc_0.67_val_loss_0.85_val_acc_0.68.h5\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.8206 - acc: 0.6682 - val_loss: 0.8467 - val_acc: 0.6797\n",
      "Epoch 42/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.7851 - acc: 0.7052Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 0.8787 - acc: 0.6532\n",
      "Epoch 00042: val_loss did not improve from 0.84666\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.7832 - acc: 0.7055 - val_loss: 0.8823 - val_acc: 0.6562\n",
      "Epoch 43/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.8000 - acc: 0.6885Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 0.8659 - acc: 0.6694\n",
      "Epoch 00043: val_loss did not improve from 0.84666\n",
      "188/188 [==============================] - 37s 199ms/step - loss: 0.8004 - acc: 0.6882 - val_loss: 0.8648 - val_acc: 0.6719\n",
      "Epoch 44/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.7702 - acc: 0.7025Epoch 1/50\n",
      " 32/188 [====>.........................] - ETA: 7s - loss: 0.8863 - acc: 0.6719\n",
      "Epoch 00044: val_loss did not improve from 0.84666\n",
      "188/188 [==============================] - 38s 199ms/step - loss: 0.7727 - acc: 0.7021 - val_loss: 0.8863 - val_acc: 0.6719\n",
      "Epoch 45/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.7676 - acc: 0.7012Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 8s - loss: 0.8355 - acc: 0.6653\n",
      "Epoch 00045: val_loss improved from 0.84666 to 0.83687, saving model to ./snapshots/model_epoch_45_loss_0.77_acc_0.70_val_loss_0.84_val_acc_0.67.h5\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.7704 - acc: 0.6995 - val_loss: 0.8369 - val_acc: 0.6680\n",
      "Epoch 46/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.7513 - acc: 0.7152Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 0.8447 - acc: 0.6734\n",
      "Epoch 00046: val_loss did not improve from 0.83687\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.7515 - acc: 0.7148 - val_loss: 0.8469 - val_acc: 0.6758\n",
      "Epoch 47/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.7443 - acc: 0.7045Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 0.8345 - acc: 0.6895\n",
      "Epoch 00047: val_loss improved from 0.83687 to 0.83264, saving model to ./snapshots/model_epoch_47_loss_0.74_acc_0.71_val_loss_0.83_val_acc_0.69.h5\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.7437 - acc: 0.7055 - val_loss: 0.8326 - val_acc: 0.6914\n",
      "Epoch 48/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.7397 - acc: 0.7092Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 0.7767 - acc: 0.6935\n",
      "Epoch 00048: val_loss improved from 0.83264 to 0.77105, saving model to ./snapshots/model_epoch_48_loss_0.74_acc_0.71_val_loss_0.77_val_acc_0.70.h5\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.7386 - acc: 0.7094 - val_loss: 0.7710 - val_acc: 0.6953\n",
      "Epoch 49/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.7397 - acc: 0.7199Epoch 1/50\n",
      " 31/188 [===>..........................] - ETA: 7s - loss: 0.8233 - acc: 0.7056\n",
      "Epoch 00049: val_loss did not improve from 0.77105\n",
      "188/188 [==============================] - 38s 199ms/step - loss: 0.7381 - acc: 0.7201 - val_loss: 0.8190 - val_acc: 0.7031\n",
      "Epoch 50/50\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.6947 - acc: 0.7293Epoch 1/50\n",
      " 32/188 [====>.........................] - ETA: 7s - loss: 0.8085 - acc: 0.6914\n",
      "Epoch 00050: val_loss did not improve from 0.77105\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 0.6953 - acc: 0.7287 - val_loss: 0.8085 - val_acc: 0.6914\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4srYh4ceGkaA"
   },
   "source": [
    "## Download Snapshot\n",
    "Download the best snapshot according to the metrics. Use the \"Files\" tab in Google Colab to open folder view and navigate to the snapshots folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yRSotaMPHMk1"
   },
   "source": [
    "## Edit scripts\n",
    "In the Files tab, you can double click on any \".py\" to edit it and save it within Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WYFszpa7FVXl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_fully_convolutional_network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
